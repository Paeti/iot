{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf0700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from statsmodels.graphics.tsaplots import plot_acf#, plot_pacf, month_plot # => noch pacf nutzen???\n",
    "from statsmodels.tsa.seasonal import STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cf7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autots import AutoTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18012798",
   "metadata": {},
   "source": [
    "# Exploration des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e1b29",
   "metadata": {},
   "source": [
    "Als erstes wird der genutzte Datensatz untersucht. Dabei werden die statistischen Eigenschaften der Zeitreihe untersucht, um gegebenfalls Rückschlüsse auf geeignete Modelle ziehen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1777c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/traffic.csv\", parse_dates=True, index_col=\"DateTime\")\n",
    "data.drop([\"ID\"], axis=1, inplace=True)\n",
    "datetime_data = data.copy()\n",
    "grouped_datetime_data = datetime_data.groupby(by=\"Junction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062e14d",
   "metadata": {},
   "source": [
    "Nachdem laden des Datensatzes wird die Spalte \"ID\" aus dem Datensatz entfernt. Da es sich um eine pro Datum eindeutige ID handelt hat dieses Attribut keinen Wert für eine Vorhersage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa72091",
   "metadata": {},
   "outputs": [],
   "source": [
    "junction_to_color_mapping = {\n",
    "    1: \"blue\",\n",
    "    2: \"green\",\n",
    "    3: \"red\",\n",
    "    4: \"darkorange\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2da63e",
   "metadata": {},
   "source": [
    "Um die vier Kreuzungen auf Diagrammen unterscheiden zu können wird jeder Kreuzung eine Farbe zugeordnet, die durchgehend verwendet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cc18978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_observation_count_per_junction_barplot(data_grouped_by_junction):\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    \n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    color_list = []\n",
    "    \n",
    "    for key, group in data_grouped_by_junction:\n",
    "        x_values.append(key)\n",
    "        y_values.append(group.size)\n",
    "        color_list.append(junction_to_color_mapping[key])\n",
    "        \n",
    "    ax.bar(x_values, y_values, color=color_list)\n",
    "    ax.set_xticks(x_values)\n",
    "    ax.set_xticklabels(\n",
    "        map(lambda x: \"Kreuzung {0}\".format(x), x_values)\n",
    "    )\n",
    "    #ax.set_title(\"Number of datapoints available in the traffic dataset per junction\", fontsize=15)\n",
    "    ax.set_xlabel(\n",
    "        \"Vorhandene Kreuzungen im \\\"traffic prediction\\\" Datensatz\", \n",
    "        fontsize=15,\n",
    "    )\n",
    "    ax.set_ylabel(\n",
    "        \"Anzahl Datenpunkte pro Kreuzung\",\n",
    "        fontsize=15,\n",
    "    )\n",
    "    \n",
    "    ax.tick_params(labelsize=13)\n",
    "    \n",
    "    plt.savefig(\"./eda_plots/traffic_dataset_datapoint_per_junction_bar_plot.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8f3f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_observation_count_per_junction_barplot(grouped_datetime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f3cc6",
   "metadata": {},
   "source": [
    "![datapoints per junction](./eda_plots/traffic_dataset_datapoint_per_junction_bar_plot.png)\n",
    "\n",
    "Dieses Diagramm zeigt, wie viele Datenpunkte pro Kreuzung im Datensatz vorhanden sind. Es zeigt sich, dass zu Kreuzung vier deutlich weniger Datenpunkte vorliegen als zu den anderen drei Kreuzungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9aaffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_plot_by_junction(data_grouped_by_junction):\n",
    "    fig, axs = plt.subplots(4, 1, figsize=(30,15))\n",
    "   \n",
    "    \n",
    "    for key, group in data_grouped_by_junction:\n",
    "        vehicle_counts = group[\"Vehicles\"].value_counts().sort_index()\n",
    "        vehicle_counts.plot(\n",
    "            kind=\"bar\", \n",
    "            ax=axs[key - 1], \n",
    "            color=junction_to_color_mapping[key],\n",
    "        )\n",
    "        \n",
    "        #fig.suptitle(\n",
    "        #    \"Distinct vehicle count value occurences per junction of the traffic dataset\",\n",
    "        #    fontsize=20,\n",
    "        #)\n",
    "        \n",
    "        axs[key - 1].set_title(\n",
    "            \"Häufigkeit bestimmter Fahrzeuganzahlen an Kreuzung {0}\".format(key), \n",
    "            fontsize=25,\n",
    "        )\n",
    "        axs[key - 1].set_xlabel(\n",
    "            \"Fahrzeuganzahlwerte\", \n",
    "            fontsize=20,\n",
    "        )\n",
    "        axs[key - 1].set_ylabel(\n",
    "            \"Häufigkeit der \\nFahrzeuganzahlwerte\", \n",
    "            fontsize=20,\n",
    "        )\n",
    "        \n",
    "        axs[key -1].tick_params(labelsize=13)\n",
    "        axs[key -1].tick_params(axis='x', labelrotation = 45)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.95)\n",
    "        \n",
    "    plt.savefig(\"./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "abad2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bar_plot_by_junction(grouped_datetime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be401d",
   "metadata": {},
   "source": [
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png)\n",
    "\n",
    "Dieses Balkendigramm zeigt die empirisch gesammelten Häufigkeiten der verschiedenen Fahrzeuganzahlen an allen vier Kreuzungen. Kreuzung eins scheint am meisten befahren zu werden. Die maximale Fahrzeuganzahl an dieser Kreuzung beträgt 156. Fahrzeuganzahlwerte zwischen 5 und ca. 117 kommen regelmäßig vor. Betrachtet man die y-Achsen Skalierung zeigt sich, dass die verschieden Fahrzeuganzahlen weniger Häufig vorkommen, als bei den anderen Kreuzungen.\n",
    "\n",
    "Kreuzung vier wird von allen Kreuzungen am wenigsten befahren. Dort sind nur Fahrzeuganzahlen von bis zu 20 regelmäßig vertreten. Amhäufigsten sind zwischen 3 und 11 Fahrzeuge an der Kreuzung. Die Tatsache, dass zu dieser Kreuzung am wenigsten Daten vorliegen dürfte keinen Einfluss auf diesen vergleich haben, da sie eher die Skalierung der y als der x-Achse beeinflussen würde.\n",
    "\n",
    "Sowohl bei Kreuzung zwei und drei liegt der Fahrzeuganzahlwert meistens im Bereich zwischen 1 und 35 Fahrzeugen. Die Skalierung der x-Achse der Diagramme zu diesen beiden Kreuzungen stimmt ebenfalls überein.\n",
    "Sie unterscheiden sich aber auch in der Hinsicht, dass Kreuzung drei sehr selten auch einen deutlich höhere Fahrzeuganzahlwert aufweist. Der maximale Wert beträgt 180. Das ist der höchste im Datensatz vorhandenen Fahzeuganzahlwert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aa528b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hist_plot_by_junction(data_grouped_by_junction):\n",
    "    fig, axs = plt.subplots(\n",
    "        2, \n",
    "        2, \n",
    "        figsize=(20,15),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "    \n",
    "    #fig.suptitle(\n",
    "    #        \"Histograms of the vehicle counts of the traffic dataset\"\n",
    "    #        \" per junction with identicall x and y axis scale\",\n",
    "    #        fontsize=30,\n",
    "    #    )\n",
    "    \n",
    "    column = 0\n",
    "    row = 0\n",
    "    \n",
    "    for key, group in data_grouped_by_junction:\n",
    "        group.hist(\n",
    "            ax=axs[column, row],\n",
    "            column=\"Vehicles\",\n",
    "            bins=25,\n",
    "            grid=False,\n",
    "            color=junction_to_color_mapping[key],\n",
    "        )\n",
    "        \n",
    "        axs[column, row].xaxis.set_tick_params(labelbottom=True)\n",
    "        axs[column, row].yaxis.set_tick_params(labelbottom=True)\n",
    "        axs[column, row].set_title(\n",
    "            \"Histogramm der Häufigkeiten \\nFahrzeuganzahlwerte an Kreuzung {0}\".format(key),\n",
    "            fontsize=25,\n",
    "        )\n",
    "        axs[column, row].set_xlabel(\"Fahrzeuganzahlwerte\", fontsize=20,)\n",
    "        axs[column, row].set_ylabel(\n",
    "            \"Häufigkeit der Fahrzeuganzahlwerte \\nin festgelegten Wertebereichen\",\n",
    "            fontsize=20,\n",
    "        )\n",
    "        \n",
    "        axs[column, row].tick_params(labelsize=16)\n",
    "    \n",
    "\n",
    "        \n",
    "        column = 0 if key % 2 == 0 else column + 1\n",
    "        row = row + 1 if column % 2 == 0 else row\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.92)\n",
    "\n",
    "    plt.savefig(\"./eda_plots/traffic_dataset_vehicle_count_per_junction_hist.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91b08c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hist_plot_by_junction(grouped_datetime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82234e3c",
   "metadata": {},
   "source": [
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_hist.png)\n",
    "\n",
    "\n",
    "Mit Hilfe dieser Histogramme wird versucht die wahre Verteilung der Fahrzeuganzahlwerte an den verschiedenen Kreuzungen anzunähern. Die allgemeine Form der Verteilungen ähnelt sich bei allen vier Kreuzungen. Sie unterscheiden sich aber deutlich bezüglich ihrer Stauchung in x-Richtung. Auf Grund dieser Tatsache könnte es sinnvoll sein pro Kreuzung ein eigenes Modell zu trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59558d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_junction_timeseries_in_one_plot(data_grouped_by_junction, time_frequence_shown):\n",
    "        fig, ax = plt.subplots(figsize=(25,12))\n",
    "        \n",
    "        frequency_mapping_dict = {\n",
    "            \"H\": \"Hour\",\n",
    "            \"D\": \"Day\",\n",
    "            \"W\": \"Week\",\n",
    "            \"M\": \"Month\",\n",
    "            \"Y\": \"Year\",\n",
    "        }\n",
    "        \n",
    "        for key, group in data_grouped_by_junction:\n",
    "            group.drop([\"Junction\"], axis=1, inplace=True)\n",
    "            resampled_data = group.resample(time_frequence_shown).mean()\n",
    "            \n",
    "            ax.plot(\n",
    "                resampled_data, \n",
    "                color = junction_to_color_mapping[key],\n",
    "                label = \"Kreuzung {0}\".format(key)\n",
    "            )\n",
    "                    \n",
    "        leg = ax.legend(fontsize=\"xx-large\")\n",
    "\n",
    "        for line in leg.get_lines():\n",
    "            line.set_linewidth(6)\n",
    "        \n",
    "        #if time_frequence_shown == \"H\":\n",
    "        #    ax.set_title(\n",
    "        #        (\"{0}ly vehicle count per junction\"        \n",
    "        #        \" in the traffic dataset\").format(frequency_mapping_dict[\"H\"]),\n",
    "        #        fontsize = 25,\n",
    "        #    )\n",
    "        #else:\n",
    "        #    ax.set_title(\n",
    "        #        (\"{0}ly vehicle count per junction\"        \n",
    "        #         \" in the traffic dataset calculated as mean of the hourly dates\").format(\n",
    "        #            frequency_mapping_dict[time_frequence_shown]\n",
    "        #        ),\n",
    "        #        fontsize = 25,\n",
    "        #    )\n",
    "        \n",
    "        ax.tick_params(labelsize=20)\n",
    "        ax.tick_params(axis='x', labelrotation = 45)\n",
    "        \n",
    "        ax.set_xlabel(\"Zeitpunkt t\", fontsize=25)\n",
    "        ax.set_ylabel(\"Anzahl Fahrzeuge zum Zeitpunkt t\", fontsize=25)\n",
    "        \n",
    "        plt.savefig(\n",
    "            (\n",
    "                \"./eda_plots/traffic_dataset_combined\"\n",
    "                \"_timeseries_plot_{0}_frequency.png\"\n",
    "            ).format(frequency_mapping_dict[time_frequence_shown])\n",
    "        )\n",
    "\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "412916fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_junction_timeseries_in_one_plot(grouped_datetime_data, \"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649d140",
   "metadata": {},
   "source": [
    "![datapoints per junction](./eda_plots/traffic_dataset_combined_timeseries_plot_Day_frequency.png)\n",
    "\n",
    "Die im letzten Abschnitt durchgeführte Untersuchung der Verteilung der Fahrzeuganzahlwerte war zeitunabhängig.\n",
    "Um zu prüfen, ob sich die Daten auch in Abhängigkeit zur Zeit deutlich unterscheiden, werden in diesem Diagramm die Zeitreihendaten pro Kreuzung dargestellt. Im Datensatz liegen die Datenpunkte mit einem Abstand von jeweils einer Stunde vor. Um das Diagramm übersichtlicher zu gestalten wurde pro Tag jeweils der Mittelwert der Fahrzeuganzahlwerte dargestellt. \n",
    "\n",
    "Diese Darstellung zeigt, dass Kreuzung eins nicht nur am stärksten befahren ist, sondern auch, dass der Verkehr im Zeitraum von November 2015 bis Juli 2017 an dieser Kreuzung am deutlichsten zugenommen hat.\n",
    "\n",
    "Die Kreuzungen drei und vie scheinen generell keinen Zuwachs an Verkehr verzeichenn zu können. Natürlich sind Tage und Wochen mit besonders viel Verkehr vorhanden, aber auf den gesamten abgebildeten Zeitraum bezogen scheint die Verkehrdichte ungefähr gleich zu bleiben. Gegebenenfalls steigt die Verkehrsdichte an der dritten Kreuzung seit dem Mai 2017, aber es leigen zu wenige Daten vor um das abschließend sagen zu können.\n",
    "\n",
    "Die Zeitreihe zu zweiten Kreuzung bleibt bis zum Januar 2017 auch eher stationär. Bis auf einzelne Ausnahmen scheint kein steigender oder fallender Trend zu beobachten sein. Ab dem Januar 2017 ändert sich das. Im Zeitraum zwischen Januar und Juli 2017 scheint das Verkehrsaufkommen an dieser Kreuzung zu steigen.\n",
    "\n",
    "Dieses Diagramm zeigt, dass es notwendig ist jeweils verschiedenen Modelle pro Kreuzung zu testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b35d7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_junction_timeseries_decomposition_in_one_plot(data_grouped_by_junction, time_frequence_shown):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows = 4, \n",
    "        ncols = 1, \n",
    "        figsize=(30,18),\n",
    "    )\n",
    "    \n",
    "    frequency_mapping_dict = {\n",
    "        \"H\": \"Hour\",\n",
    "        \"D\": \"Day\",\n",
    "        \"W\": \"Week\",\n",
    "        \"M\": \"Month\",\n",
    "        \"Y\": \"Year\",\n",
    "    }\n",
    "    \n",
    "    for key, group in data_grouped_by_junction:\n",
    "        group.drop([\"Junction\"], axis=1, inplace=True)\n",
    "        resampled_data = group.resample(time_frequence_shown).mean()\n",
    "        decomposed_ts = STL(resampled_data).fit()\n",
    "        \n",
    "        axs[0].plot(\n",
    "            decomposed_ts.observed,\n",
    "            color = junction_to_color_mapping[key],\n",
    "            label = \"Kreuzung {0}\".format(key),\n",
    "        )\n",
    "        axs[1].plot(\n",
    "            decomposed_ts.trend,\n",
    "            color = junction_to_color_mapping[key],\n",
    "        )\n",
    "        axs[2].plot(\n",
    "            decomposed_ts.seasonal,\n",
    "            color = junction_to_color_mapping[key],\n",
    "        )\n",
    "        axs[3].plot(\n",
    "            decomposed_ts.resid,\n",
    "            color = junction_to_color_mapping[key],\n",
    "        )\n",
    "        \n",
    "        \n",
    "    #if time_frequence_shown == \"H\":\n",
    "    #        fig.suptitle(\n",
    "    #            (\"Decomposition of the {0}ly vehicle count data per junction\"        \n",
    "    #            \" in the traffic dataset\").format(frequency_mapping_dict[\"H\"]),\n",
    "    #            fontsize = 30,\n",
    "    #            y = 0.92,\n",
    "    #        )\n",
    "    #else:\n",
    "    #    fig.suptitle(\n",
    "    #        (\"Decomposition of the {0}ly vehicle count data per junction\"        \n",
    "    #         \" in the traffic dataset calculated as mean of the hourly dates\").format(\n",
    "    #            frequency_mapping_dict[time_frequence_shown]\n",
    "    #        ),\n",
    "    #        fontsize = 30,\n",
    "    #        y = 0.92,\n",
    "    #    )\n",
    "    \n",
    "    axs[0].set_title(\"Beobachtete Zeitreihendaten pro Kreuzung\", fontsize=24)\n",
    "    axs[1].set_title(\"Trend Komponente der Zeitreihendaten pro Kreuzung\", fontsize=24)\n",
    "    axs[2].set_title(\"Saison Komponente der Zeitreihendaten pro Kreuzung\", fontsize=24)\n",
    "    axs[3].set_title(\"Irreguläre Komponente der Zeitreihendaten pro Kreuzung\", fontsize=24)\n",
    "    \n",
    "    #axs[0].set_ylabel(\"Fahrzeuganzahl zum \\nZeitpunkt t\", fontsize=20)\n",
    "    #axs[1].set_ylabel(\"Fahrzeuganzahl zum \\nZeitpunkt t\", fontsize=20)\n",
    "    #axs[2].set_ylabel(\"Fahrzeuganzahl zum \\nZeitpunkt t\", fontsize=20)\n",
    "    axs[3].set_xlabel(\"Zeitpunkt t der Datenaufzeichnung\", fontsize=20)\n",
    "    #axs[3].set_ylabel(\"Fahrzeuganzahl zum \\nZeitpunkt t\", fontsize=20)\n",
    "    \n",
    "    axs[0].tick_params(labelsize=20)\n",
    "    axs[1].tick_params(labelsize=20)\n",
    "    axs[2].tick_params(labelsize=20)\n",
    "    axs[3].tick_params(labelsize=20)\n",
    "        \n",
    "    leg = fig.legend(\n",
    "        fontsize=\"xx-large\", \n",
    "        ncol = 2,\n",
    "        bbox_to_anchor =(0.6, 0.095)\n",
    "    )\n",
    "    \n",
    "    for line in leg.get_lines():\n",
    "            line.set_linewidth(6)\n",
    "            \n",
    "    # y-achsen beschriftung anpassen!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "            \n",
    "    fig.tight_layout(h_pad=2.0)\n",
    "    fig.subplots_adjust(bottom=0.15)\n",
    "    \n",
    "    plt.savefig(\n",
    "        \"./eda_plots/timeseries_decomposition_per_junction.png\",\n",
    "        facecolor = \"w\",\n",
    "    )\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3bff11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_junction_timeseries_decomposition_in_one_plot(grouped_datetime_data, \"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063c82d",
   "metadata": {},
   "source": [
    "![datapoints per junction](./eda_plots/timeseries_decomposition_per_junction.png)\n",
    "\n",
    "Da es sich bei dem vorliegenden Datensatz um Univariate Zeitreihendaten handelt, können Vorhersagen über zukünftige Werte nur auf Grundlage der vergangenen Werte getroffen werden. Um den der Zeitreihe zu Grunde liegenden stochastischen Prozess anzunähern muss eine Funktion an Hand der vorliegenden Daten so angepasst werden, dass mit den p letzten Datenpunkten als Eingabe eine möglichst gute Vorhersage für den Zeitpunkt t + 1 als Ausgabe liefert.\n",
    "Von einfachen Methoden wie dem Durchschnitt der letzten p Datenpunkte bis zu Neuronalen Netzen gibt es verschieden komplexe Modelle um die wahre erzeugende Funktion anzunähern.\n",
    "Je komplexer diese wahre Funktion ist, desto komplexer müssen die Modelle sein, mit deren Hilfe sie angenähert werden soll. Komplexität bedeutet in diesem Kontext, dass das Verhalten zum Zeitpunkt t + 1 keinem einfachen Muster folgt. Ein einfaches Muster wäre in diesem Kontext z.B. wenn sich der Fahrzeuganzahlwert alle sieben Tage mit einer Abweichung von maximal +- zwei Fahrezeugen gleicht.\n",
    "\n",
    "Eine Dekomposition der Zeitreihendaten in einen generellen Trend Anteil, einen Saisonalen Anteil und einen Irregulären Anteil kann so Aufschluss darüber geben, welche Art von Modellen geeignet seien könnten. Natürlich ist dies kein definitiver Beweis für die Eignung eines bestimmten Modells.\n",
    "Diese Dekomposition folgt entweder einem additiven oder einem multiplikativen Modell.\n",
    "Im Falle eines additiven Modells, ergibt sich der wahre Fahrzeuganzahlwert zum Zeitpunkt t folgendermaßen:\n",
    "\n",
    "$Fahrzeuganzahlwert_t = {Trend Anteil}_t + {Saisonaler Anteil}_t + {Irregulärer Anteil}_t$\n",
    "\n",
    "Dementsprechend sieht der Ansatz eines multiplikativen Modells wie folgt aus:\n",
    "\n",
    "$Fahrzeuganzahlwert_t = {Trend Anteil}_t \\cdot {Saisonaler Anteil}_t \\cdot {Irregulärer Anteil}_t$\n",
    "\n",
    "Das obige Diagramm zeigt eine additive Dekomposition für alle vier Kreuzungen. Die Datenpunkte wurden wieder durch Mittelwertbildung auf eine tägliche Frequenz reduziert. Die Beobachtungen, die an Hand des vorherigen Zeitreihendiagramms bezüglich der generellen Entwicklung der Verkehrsdichte gemacht wurden, werden von den aus diesem Diagramm ablesbaren Trend Komponenten der Zeitreihendaten pro Kreuzung unterstützt.\n",
    "\n",
    "Auch die Beobachtung der wachsenden Vekehrsdichte an Kreuzung eins über den aufgezeichneten Zeitraum ist auf der Darstellung der Saisonalen Komponentze zu sehen.Diese Darstellung zeigt auch, dass die Vekehrsdichte an Kreuzung zwei ebenfalls über den aufgezeichneten Zeitraum kontinuierlich steigt. Diese Tatsache war im Diagramm der kompletten Zeitreihe nicht so deutlich abzulesen.\n",
    "\n",
    "Die Darstellung der Irregulären Komponente zeigt, dass vorallem an Kreuzung eins und drei verhältnissmäßig oft ein nicht zu vernachlässigender Anteil des Fahrzeuganzahlwertes nicht auf den kombinierten Trend und Saison Anteil zurückzuführen ist.\n",
    "\n",
    "Insgesamt lässt dieses Diagramm die Vermutung zu, dass für die Kreuzungen zwei und vier gegebenenfalls einfacherere Modelle ausreichen. Da ein Großteil des Fahrzeuganzahlwertes nur auf dem Trend und dem Saisonalen Komponenten beruht, muss das Modell wahrscheinlich keine allzu komplexe Funktion annähern.\n",
    "Die teilweise großen Werte des Irregulären Anteils bei den Kreuzungen eins und drei lässt vermuten, dass die Modelle, die diese Zeitreihe annähern unter Umständen deutlich komplizierter seien müssen, oder die trainierten Modelle für diese Kreuzungen keine so zuverlässigen Werte vorhersagen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8747b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autocorrelation_by_junctions(\n",
    "    data_grouped_by_junction,\n",
    "    frequency,\n",
    "    lag,\n",
    "):\n",
    "    fig, axs = plt.subplots(\n",
    "        2, \n",
    "        2, \n",
    "        figsize=(20,10),\n",
    "    )\n",
    "    \n",
    "    #fig.suptitle(\n",
    "     #       \"Histograms of the vehicle counts of the traffic dataset\"\n",
    "     #       \" per junction with identicall x and y axis scale\",\n",
    "      #      fontsize=20,\n",
    "     #   )\n",
    "    \n",
    "    frequency_mapping_dict = {\n",
    "        \"H\": \"Stunde\",\n",
    "        \"D\": \"Tag\",\n",
    "        \"W\": \"Woche\",\n",
    "        \"M\": \"Monat\",\n",
    "        \"Y\": \"Jahr\",\n",
    "    }\n",
    "    \n",
    "    frequency_mapping_dict_plural = {\n",
    "        \"H\": \"Stunden\",\n",
    "        \"D\": \"Tage\",\n",
    "        \"W\": \"Wochen\",\n",
    "        \"M\": \"Monate\",\n",
    "        \"Y\": \"Jahre\",\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    column = 0\n",
    "    row = 0\n",
    "    \n",
    "    for key, group in data_grouped_by_junction:\n",
    "        #axs[column, row].set_title(\n",
    "        #    \"Histogram for vehicle count data at junction {0}\".format(key),\n",
    "        #    fontsize=18,\n",
    "        #)\n",
    "        \n",
    "        resampled_data = group.resample(frequency).mean()\n",
    "\n",
    "        plot_acf(\n",
    "            group[\"Vehicles\"], \n",
    "            lags=lag,\n",
    "            ax=axs[column, row],\n",
    "            auto_ylims=True,\n",
    "            vlines_kwargs = {\"colors\": junction_to_color_mapping[key]},\n",
    "            color=junction_to_color_mapping[key],\n",
    "        )\n",
    "        \n",
    "        axs[column, row].set_title(\n",
    "            \"Autokorrelation der Zeitreihe an Kreuzung {0}\".format(key),\n",
    "            fontsize = 25,\n",
    "        )\n",
    "        axs[column, row].set_ylabel(\"Autokorrelationswert\", fontsize=20)\n",
    "        axs[column, row].set_xlabel(\n",
    "            \"Bezugszeitpunkt {0} t - {1} {2}\".format(\n",
    "                frequency_mapping_dict[frequency],\n",
    "                lag,\n",
    "                frequency_mapping_dict_plural[frequency],\n",
    "            ), \n",
    "            fontsize=20,\n",
    "        )\n",
    "\n",
    "        axs[column, row].tick_params(labelsize=15)\n",
    "        \n",
    "        column = 0 if key % 2 == 0 else column + 1\n",
    "        row = row + 1 if column % 2 == 0 else row\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.95)\n",
    "    \n",
    "    plt.savefig(\n",
    "        \"./eda_plots/traffic_dataset_autocorrelation_per_junction_plot_{0}_{1}.png\".format(\n",
    "            frequency,\n",
    "            lag,\n",
    "        )\n",
    "    )\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6bcd1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autocorrelation_by_junctions(grouped_datetime_data, \"D\", 7)\n",
    "plot_autocorrelation_by_junctions(grouped_datetime_data, \"D\", 30)\n",
    "plot_autocorrelation_by_junctions(grouped_datetime_data, \"M\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33300c",
   "metadata": {},
   "source": [
    "![datapoints per junction](./eda_plots/traffic_dataset_autocorrelation_per_junction_plot_D_7.png)\n",
    "\n",
    "\n",
    "![datapoints per junction](./eda_plots/traffic_dataset_autocorrelation_per_junction_plot_D_30.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09067081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# => stat test ob statisch? => hätte das implikationen oder kann das durch preprocessing egal gemacht werden????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6cd62",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eacf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_weighting: dict = {\n",
    "#            'smape_weighting': 5,\n",
    "#            'mae_weighting': 2,\n",
    "#            'rmse_weighting': 2,\n",
    "#            'made_weighting': 0.5,\n",
    "#            'mage_weighting': 0,\n",
    "#            'mle_weighting': 0,\n",
    "#            'imle_weighting': 0,\n",
    "#            'spl_weighting': 3,\n",
    "#            'containment_weighting': 0,\n",
    "#            'contour_weighting': 1,\n",
    "#            'runtime_weighting': 0.05,\n",
    "#            'oda_weighting': 0.001,\n",
    "#        },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "019bf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_filesystem_for_saving_results():\n",
    "    for junction_number in range(1, 5):\n",
    "        junction_result_folder = \"./results_per_junction/junction_{0}\".format(junction_number) \n",
    "        \n",
    "        if not os.path.exists(junction_result_folder):\n",
    "            os.makedirs(junction_result_folder)\n",
    "            print(\"Directory {0} succesfully created.\".format(junction_result_folder))\n",
    "        else:    \n",
    "            print(\"Directory {0} already exists.\".format(junction_result_folder))\n",
    "            \n",
    "    for junction_result_folder in os.listdir(\"./results_per_junction\"):\n",
    "        try:\n",
    "            os.mkdir(\"./results_per_junction/{0}/autots_model\".format(junction_result_folder))\n",
    "            os.mkdir(\"./results_per_junction/{0}/best_quarter_of_trained_models\".format(junction_result_folder))\n",
    "            os.mkdir(\"./results_per_junction/{0}/result_plots\".format(junction_result_folder))\n",
    "            os.mkdir(\n",
    "                \"./results_per_junction/{0}/\"\n",
    "                \"result_tables_as_latex\".format(junction_result_folder)\n",
    "            )\n",
    "            print(\n",
    "                \"Directories ./results_per_junction/{0}/autots_model,\"\n",
    "                \" ./results_per_junction/{0}/result_plots,\"\n",
    "                \" ./results_per_junction/{0}/best_quarter_of_trained_models\"\n",
    "                \"and ./results_per_junction/{0}/result_tables_as_latex\"\n",
    "                \" successfully created.\".format(junction_result_folder)\n",
    "            )\n",
    "        except FileExistsError:\n",
    "            print(\n",
    "                \"Directories ./results_per_junction/{0}/autots_model,\"\n",
    "                \" ./results_per_junction/{0}/result_plots,\"\n",
    "                \" ./results_per_junction/{0}/best_quarter_of_trained_models\"\n",
    "                \"and ./results_per_junction/{0}/result_tables_as_latex\" \n",
    "                \" already existed.\".format(junction_result_folder)\n",
    "            )  \n",
    "    \n",
    "    try:\n",
    "        os.mkdir(\"./combined_result_plots\")\n",
    "        print(\"Directory ./combined_result_plots successfully created.\")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory ./combined_result_plots already existed\")  \n",
    "    \n",
    "\n",
    "def cleanup_filesystem():\n",
    "    try:\n",
    "        shutil.rmtree(\"./combined_result_plots\")\n",
    "    except OSError as e:\n",
    "        print(\"Error: {0} : {1}\".format(\"./combined_result_plots\", e.strerror))\n",
    "        \n",
    "    try:\n",
    "        shutil.rmtree(\"./results_per_junction\")\n",
    "    except OSError as e:\n",
    "        print(\"Error: {0} : {1}\".format(\"./results_per_junction\", e.strerror))\n",
    "\n",
    "\n",
    "def save_autots_model_results_per_single_junction(\n",
    "    autots_model_single_junction,\n",
    "    junction_key,\n",
    "):\n",
    "    filename = (\"junction_{0}_trained_autots_model_junction_\"       \n",
    "                    \"number_tuple.bin\").format(junction_key)\n",
    "        \n",
    "    working_directory =os.getcwd()  # da lassen? eig nicht nötig?!\n",
    "    base_path = \"results_per_junction/junction_{0}/autots_model\".format(junction_key)\n",
    "        \n",
    "    complete_path = \"/\".join([working_directory, base_path, filename])\n",
    "        \n",
    "    with open(complete_path, \"wb\") as f: # \"wb\" because we want to write in binary mode\n",
    "        pickle.dump((autots_model_single_junction, junction_key), f)\n",
    "            \n",
    "            \n",
    "        \n",
    "def save_best_model_per_junctions_backforecast(\n",
    "    best_model_single_junction,\n",
    "    junction_num,\n",
    "    #time_series_data_per_junction,\n",
    "):\n",
    "    filename = (\"junction_{0}_best_trained_model_junction_\"       \n",
    "                    \"backforecast.csv\").format(junction_num)\n",
    "        \n",
    "    working_directory =os.getcwd()  # da lassen? eig nicht nötig?!\n",
    "    base_path = \"results_per_junction/junction_{0}/autots_model\".format(junction_num)\n",
    "        \n",
    "    complete_path = \"/\".join([working_directory, base_path, filename])\n",
    "                \n",
    "    junction_backforecast = best_model_single_junction.back_forecast(\n",
    "        column = \"Vehicles\",\n",
    "        n_splits = \"auto\",\n",
    "    ).forecast\n",
    "        \n",
    "    junction_backforecast.to_csv(complete_path)\n",
    "        \n",
    "\n",
    "\n",
    "def train_models_per_junction(data_grouped_by_junction, autots_param_dict):\n",
    "    result_model_junction_key_list = []\n",
    "    \n",
    "    for key, group in data_grouped_by_junction:\n",
    "        group.drop([\"Junction\"], axis=1, inplace=True)\n",
    "        group[\"Vehicles\"] = group[\"Vehicles\"].astype(\"float64\")\n",
    "\n",
    "        autots_model = AutoTS(**autots_param_dict)\n",
    "        \n",
    "        junction_resulting_model = autots_model.fit(group)\n",
    "        \n",
    "        save_autots_model_results_per_single_junction(\n",
    "            junction_resulting_model, \n",
    "            key\n",
    "        )\n",
    "        \n",
    "        save_best_model_per_junctions_backforecast(\n",
    "            junction_resulting_model, \n",
    "            key,\n",
    "        )\n",
    "        \n",
    "        result_model_junction_key_list.append((junction_resulting_model, key))\n",
    "        \n",
    "    return result_model_junction_key_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f43e8809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./results_per_junction/junction_1 succesfully created.\n",
      "Directory ./results_per_junction/junction_2 succesfully created.\n",
      "Directory ./results_per_junction/junction_3 succesfully created.\n",
      "Directory ./results_per_junction/junction_4 succesfully created.\n",
      "Directories ./results_per_junction/junction_4/autots_model, ./results_per_junction/junction_4/result_plots, ./results_per_junction/junction_4/best_quarter_of_trained_modelsand ./results_per_junction/junction_4/result_tables_as_latex successfully created.\n",
      "Directories ./results_per_junction/junction_2/autots_model, ./results_per_junction/junction_2/result_plots, ./results_per_junction/junction_2/best_quarter_of_trained_modelsand ./results_per_junction/junction_2/result_tables_as_latex successfully created.\n",
      "Directories ./results_per_junction/junction_1/autots_model, ./results_per_junction/junction_1/result_plots, ./results_per_junction/junction_1/best_quarter_of_trained_modelsand ./results_per_junction/junction_1/result_tables_as_latex successfully created.\n",
      "Directories ./results_per_junction/junction_3/autots_model, ./results_per_junction/junction_3/result_plots, ./results_per_junction/junction_3/best_quarter_of_trained_modelsand ./results_per_junction/junction_3/result_tables_as_latex successfully created.\n",
      "Directory ./combined_result_plots successfully created.\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'ConstantNaive': 1,\n",
    "    'LastValueNaive': 1.5,\n",
    "    'AverageValueNaive': 1,\n",
    "    'GLS': 1,\n",
    "    'SeasonalNaive': 1,\n",
    "    'GLM': 1,\n",
    "    'ETS': 1,\n",
    "    'UnobservedComponents': 0.4,  # it's fast enough but I'll leave for parallel\n",
    "    'WindowRegression': 0.3,  # this gets slow with Transformer, KerasRNN\n",
    "    'DatepartRegression': 0.5,\n",
    "    'UnivariateMotif': 1,\n",
    "    'SectionalMotif': 1,\n",
    "    'NVAR': 1,\n",
    "    'FBProphet': 1,\n",
    "}\n",
    "    \n",
    "\n",
    "autots_param_dict = {\n",
    "    \"forecast_length\": 5,\n",
    "    \"frequency\": \"H\",\n",
    "    \"prediction_interval\": 0.9,\n",
    "    \"ensemble\": None,\n",
    "    \"model_list\": \"superfast\",\n",
    "    \"transformer_list\": \"superfast\",\n",
    "    \"max_generations\": 5,\n",
    "    \"num_validations\": 5,\n",
    "    \"validation_method\": \"backwards\",\n",
    "    \"n_jobs\": 2,\n",
    "    \"no_negatives\": True,\n",
    "    \"holiday_country\": \"US\",\n",
    "}\n",
    "\n",
    "\n",
    "#cleanup_filesystem()\n",
    "\n",
    "prepare_filesystem_for_saving_results()\n",
    "\n",
    "#resulting_models = train_models_per_junction(grouped_datetime_data, autots_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "509e4958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3,                      Junction  Vehicles\n",
      "DateTime                               \n",
      "2015-11-01 00:00:00         3         9\n",
      "2015-11-01 01:00:00         3         7\n",
      "2015-11-01 02:00:00         3         5\n",
      "2015-11-01 03:00:00         3         1\n",
      "2015-11-01 04:00:00         3         2\n",
      "...                       ...       ...\n",
      "2017-06-30 19:00:00         3        33\n",
      "2017-06-30 20:00:00         3        31\n",
      "2017-06-30 21:00:00         3        28\n",
      "2017-06-30 22:00:00         3        26\n",
      "2017-06-30 23:00:00         3        39\n",
      "\n",
      "[14592 rows x 2 columns])]\n"
     ]
    }
   ],
   "source": [
    "data_junction_3 = [(3, grouped_datetime_data.get_group(3))]\n",
    "\n",
    "print(data_junction_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6c78bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 1 with model AverageValueNaive in generation 0 of 5\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paettfish/.local/share/virtualenvs/experiments-mVQQwhcP/lib/python3.9/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/tmp/ipykernel_1392071/1104939445.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group[\"Vehicles\"] = group[\"Vehicles\"].astype(\"float64\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 3 with model AverageValueNaive in generation 0 of 5\n",
      "Model Number: 4 with model GLS in generation 0 of 5\n",
      "Model Number: 5 with model GLS in generation 0 of 5\n",
      "Model Number: 6 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 7 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 8 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 9 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 10 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 11 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 12 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 13 with model ConstantNaive in generation 0 of 5\n",
      "Model Number: 14 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 15 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 16 with model ConstantNaive in generation 0 of 5\n",
      "Model Number: 17 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 18 with model AverageValueNaive in generation 0 of 5\n",
      "Model Number: 19 with model GLS in generation 0 of 5\n",
      "Model Number: 20 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 21 with model GLS in generation 0 of 5\n",
      "Model Number: 22 with model ConstantNaive in generation 0 of 5\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 24 with model GLS in generation 0 of 5\n",
      "Model Number: 25 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 26 with model GLS in generation 0 of 5\n",
      "Model Number: 27 with model GLS in generation 0 of 5\n",
      "Model Number: 28 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 29 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 30 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 31 with model GLS in generation 0 of 5\n",
      "Model Number: 32 with model ConstantNaive in generation 0 of 5\n",
      "Model Number: 33 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 34 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 5\n",
      "Model Number: 36 with model SeasonalNaive in generation 0 of 5\n",
      "Model Number: 37 with model LastValueNaive in generation 0 of 5\n",
      "Model Number: 38 with model GLS in generation 0 of 5\n",
      "Model Number: 39 with model AverageValueNaive in generation 0 of 5\n",
      "Model Number: 40 with model ConstantNaive in generation 0 of 5\n",
      "New Generation: 1 of 5\n",
      "Model Number: 41 with model SeasonalNaive in generation 1 of 5\n",
      "Model Number: 42 with model AverageValueNaive in generation 1 of 5\n",
      "Model Number: 43 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 44 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 45 with model GLS in generation 1 of 5\n",
      "Model Number: 46 with model GLS in generation 1 of 5\n",
      "Model Number: 47 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 48 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 49 with model AverageValueNaive in generation 1 of 5\n",
      "Model Number: 50 with model SeasonalNaive in generation 1 of 5\n",
      "Model Number: 51 with model SeasonalNaive in generation 1 of 5\n",
      "Model Number: 52 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 53 with model SeasonalNaive in generation 1 of 5\n",
      "Model Number: 54 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 55 with model GLS in generation 1 of 5\n",
      "Model Number: 56 with model SeasonalNaive in generation 1 of 5\n",
      "Model Number: 57 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 58 with model SeasonalNaive in generation 1 of 5\n",
      "Model Number: 59 with model GLS in generation 1 of 5\n",
      "Model Number: 60 with model ConstantNaive in generation 1 of 5\n",
      "Model Number: 61 with model GLS in generation 1 of 5\n",
      "Model Number: 62 with model ConstantNaive in generation 1 of 5\n",
      "Model Number: 63 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 64 with model LastValueNaive in generation 1 of 5\n",
      "Model Number: 65 with model LastValueNaive in generation 1 of 5\n",
      "New Generation: 2 of 5\n",
      "Model Number: 66 with model GLS in generation 2 of 5\n",
      "Model Number: 67 with model GLS in generation 2 of 5\n",
      "Model Number: 68 with model GLS in generation 2 of 5\n",
      "Model Number: 69 with model SeasonalNaive in generation 2 of 5\n",
      "Model Number: 70 with model ConstantNaive in generation 2 of 5\n",
      "Model Number: 71 with model SeasonalNaive in generation 2 of 5\n",
      "Model Number: 72 with model GLS in generation 2 of 5\n",
      "Model Number: 73 with model ConstantNaive in generation 2 of 5\n",
      "Model Number: 74 with model SeasonalNaive in generation 2 of 5\n",
      "Model Number: 75 with model SeasonalNaive in generation 2 of 5\n",
      "Model Number: 76 with model LastValueNaive in generation 2 of 5\n",
      "Model Number: 77 with model SeasonalNaive in generation 2 of 5\n",
      "Model Number: 78 with model SeasonalNaive in generation 2 of 5\n",
      "Model Number: 79 with model AverageValueNaive in generation 2 of 5\n",
      "Model Number: 80 with model LastValueNaive in generation 2 of 5\n",
      "Model Number: 81 with model GLS in generation 2 of 5\n",
      "Model Number: 82 with model GLS in generation 2 of 5\n",
      "Model Number: 83 with model GLS in generation 2 of 5\n",
      "Model Number: 84 with model LastValueNaive in generation 2 of 5\n",
      "Model Number: 85 with model AverageValueNaive in generation 2 of 5\n",
      "Model Number: 86 with model SeasonalNaive in generation 2 of 5\n",
      "Model Number: 87 with model LastValueNaive in generation 2 of 5\n",
      "Model Number: 88 with model ConstantNaive in generation 2 of 5\n",
      "Model Number: 89 with model LastValueNaive in generation 2 of 5\n",
      "Model Number: 90 with model AverageValueNaive in generation 2 of 5\n",
      "New Generation: 3 of 5\n",
      "Model Number: 91 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 92 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 93 with model SeasonalNaive in generation 3 of 5\n",
      "Model Number: 94 with model AverageValueNaive in generation 3 of 5\n",
      "Model Number: 95 with model SeasonalNaive in generation 3 of 5\n",
      "Model Number: 96 with model ConstantNaive in generation 3 of 5\n",
      "Model Number: 97 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 98 with model GLS in generation 3 of 5\n",
      "Model Number: 99 with model GLS in generation 3 of 5\n",
      "Model Number: 100 with model AverageValueNaive in generation 3 of 5\n",
      "Model Number: 101 with model GLS in generation 3 of 5\n",
      "Model Number: 102 with model SeasonalNaive in generation 3 of 5\n",
      "Model Number: 103 with model GLS in generation 3 of 5\n",
      "Model Number: 104 with model SeasonalNaive in generation 3 of 5\n",
      "Model Number: 105 with model SeasonalNaive in generation 3 of 5\n",
      "Model Number: 106 with model ConstantNaive in generation 3 of 5\n",
      "Model Number: 107 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 108 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 109 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 110 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 111 with model ConstantNaive in generation 3 of 5\n",
      "Model Number: 112 with model LastValueNaive in generation 3 of 5\n",
      "Model Number: 113 with model ConstantNaive in generation 3 of 5\n",
      "Model Number: 114 with model AverageValueNaive in generation 3 of 5\n",
      "Model Number: 115 with model LastValueNaive in generation 3 of 5\n",
      "New Generation: 4 of 5\n",
      "Model Number: 116 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 117 with model GLS in generation 4 of 5\n",
      "Model Number: 118 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 119 with model ConstantNaive in generation 4 of 5\n",
      "Model Number: 120 with model LastValueNaive in generation 4 of 5\n",
      "Model Number: 121 with model ConstantNaive in generation 4 of 5\n",
      "Model Number: 122 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 123 with model LastValueNaive in generation 4 of 5\n",
      "Model Number: 124 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 125 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 126 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 127 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 128 with model LastValueNaive in generation 4 of 5\n",
      "Model Number: 129 with model LastValueNaive in generation 4 of 5\n",
      "Model Number: 130 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 131 with model LastValueNaive in generation 4 of 5\n",
      "Model Number: 132 with model ConstantNaive in generation 4 of 5\n",
      "Model Number: 133 with model AverageValueNaive in generation 4 of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 134 with model AverageValueNaive in generation 4 of 5\n",
      "Model Number: 135 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 136 with model LastValueNaive in generation 4 of 5\n",
      "Model Number: 137 with model LastValueNaive in generation 4 of 5\n",
      "Model Number: 138 with model AverageValueNaive in generation 4 of 5\n",
      "Model Number: 139 with model SeasonalNaive in generation 4 of 5\n",
      "Model Number: 140 with model GLS in generation 4 of 5\n",
      "New Generation: 5 of 5\n",
      "Model Number: 141 with model LastValueNaive in generation 5 of 5\n",
      "Model Number: 142 with model LastValueNaive in generation 5 of 5\n",
      "Model Number: 143 with model LastValueNaive in generation 5 of 5\n",
      "Model Number: 144 with model GLS in generation 5 of 5\n",
      "Model Number: 145 with model AverageValueNaive in generation 5 of 5\n",
      "Model Number: 146 with model LastValueNaive in generation 5 of 5\n",
      "Model Number: 147 with model SeasonalNaive in generation 5 of 5\n",
      "Model Number: 148 with model GLS in generation 5 of 5\n",
      "Model Number: 149 with model SeasonalNaive in generation 5 of 5\n",
      "Model Number: 150 with model LastValueNaive in generation 5 of 5\n",
      "Model Number: 151 with model LastValueNaive in generation 5 of 5\n",
      "Model Number: 152 with model AverageValueNaive in generation 5 of 5\n",
      "Model Number: 153 with model ConstantNaive in generation 5 of 5\n",
      "Model Number: 154 with model AverageValueNaive in generation 5 of 5\n",
      "Model Number: 155 with model SeasonalNaive in generation 5 of 5\n",
      "Model Number: 156 with model SeasonalNaive in generation 5 of 5\n",
      "Model Number: 157 with model AverageValueNaive in generation 5 of 5\n",
      "Model Number: 158 with model ConstantNaive in generation 5 of 5\n",
      "Model Number: 159 with model LastValueNaive in generation 5 of 5\n",
      "Model Number: 160 with model SeasonalNaive in generation 5 of 5\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 24 with model LastValueNaive for Validation 1\n",
      "📈 1 - LastValueNaive with avg smape 50.97: \n",
      "Model Number: 2 of 24 with model LastValueNaive for Validation 1\n",
      "📈 2 - LastValueNaive with avg smape 49.58: \n",
      "Model Number: 3 of 24 with model LastValueNaive for Validation 1\n",
      "3 - LastValueNaive with avg smape 49.58: \n",
      "Model Number: 4 of 24 with model SeasonalNaive for Validation 1\n",
      "📈 4 - SeasonalNaive with avg smape 10.0: \n",
      "Model Number: 5 of 24 with model LastValueNaive for Validation 1\n",
      "5 - LastValueNaive with avg smape 46.41: \n",
      "Model Number: 6 of 24 with model LastValueNaive for Validation 1\n",
      "6 - LastValueNaive with avg smape 46.41: \n",
      "Model Number: 7 of 24 with model LastValueNaive for Validation 1\n",
      "7 - LastValueNaive with avg smape 46.41: \n",
      "Model Number: 8 of 24 with model SeasonalNaive for Validation 1\n",
      "8 - SeasonalNaive with avg smape 35.16: \n",
      "Model Number: 9 of 24 with model SeasonalNaive for Validation 1\n",
      "9 - SeasonalNaive with avg smape 10.64: \n",
      "Model Number: 10 of 24 with model SeasonalNaive for Validation 1\n",
      "📈 10 - SeasonalNaive with avg smape 8.93: \n",
      "Model Number: 11 of 24 with model SeasonalNaive for Validation 1\n",
      "11 - SeasonalNaive with avg smape 8.93: \n",
      "Model Number: 12 of 24 with model SeasonalNaive for Validation 1\n",
      "12 - SeasonalNaive with avg smape 49.37: \n",
      "Model Number: 13 of 24 with model ConstantNaive for Validation 1\n",
      "13 - ConstantNaive with avg smape 46.4: \n",
      "Model Number: 14 of 24 with model AverageValueNaive for Validation 1\n",
      "14 - AverageValueNaive with avg smape 72.99: \n",
      "Model Number: 15 of 24 with model GLS for Validation 1\n",
      "15 - GLS with avg smape 10.36: \n",
      "Model Number: 16 of 24 with model ConstantNaive for Validation 1\n",
      "16 - ConstantNaive with avg smape 70.01: \n",
      "Model Number: 17 of 24 with model ConstantNaive for Validation 1\n",
      "17 - ConstantNaive with avg smape 70.01: \n",
      "Model Number: 18 of 24 with model ConstantNaive for Validation 1\n",
      "18 - ConstantNaive with avg smape 70.01: \n",
      "Model Number: 19 of 24 with model AverageValueNaive for Validation 1\n",
      "19 - AverageValueNaive with avg smape 69.99: \n",
      "Model Number: 20 of 24 with model AverageValueNaive for Validation 1\n",
      "20 - AverageValueNaive with avg smape 69.99: \n",
      "Model Number: 21 of 24 with model AverageValueNaive for Validation 1\n",
      "21 - AverageValueNaive with avg smape 15.34: \n",
      "Model Number: 22 of 24 with model AverageValueNaive for Validation 1\n",
      "22 - AverageValueNaive with avg smape 77.77: \n",
      "Model Number: 23 of 24 with model AverageValueNaive for Validation 1\n",
      "📈 23 - AverageValueNaive with avg smape 6.42: \n",
      "Model Number: 24 of 24 with model GLS for Validation 1\n",
      "📈 24 - GLS with avg smape 6.17: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 24 with model LastValueNaive for Validation 2\n",
      "📈 1 - LastValueNaive with avg smape 46.51: \n",
      "Model Number: 2 of 24 with model LastValueNaive for Validation 2\n",
      "2 - LastValueNaive with avg smape 51.58: \n",
      "Model Number: 3 of 24 with model LastValueNaive for Validation 2\n",
      "3 - LastValueNaive with avg smape 51.58: \n",
      "Model Number: 4 of 24 with model SeasonalNaive for Validation 2\n",
      "4 - SeasonalNaive with avg smape 84.48: \n",
      "Model Number: 5 of 24 with model LastValueNaive for Validation 2\n",
      "5 - LastValueNaive with avg smape 57.9: \n",
      "Model Number: 6 of 24 with model LastValueNaive for Validation 2\n",
      "6 - LastValueNaive with avg smape 57.9: \n",
      "Model Number: 7 of 24 with model LastValueNaive for Validation 2\n",
      "7 - LastValueNaive with avg smape 57.9: \n",
      "Model Number: 8 of 24 with model SeasonalNaive for Validation 2\n",
      "8 - SeasonalNaive with avg smape 86.39: \n",
      "Model Number: 9 of 24 with model SeasonalNaive for Validation 2\n",
      "9 - SeasonalNaive with avg smape 83.94: \n",
      "Model Number: 10 of 24 with model SeasonalNaive for Validation 2\n",
      "10 - SeasonalNaive with avg smape 84.48: \n",
      "Model Number: 11 of 24 with model SeasonalNaive for Validation 2\n",
      "11 - SeasonalNaive with avg smape 84.48: \n",
      "Model Number: 12 of 24 with model SeasonalNaive for Validation 2\n",
      "12 - SeasonalNaive with avg smape 56.28: \n",
      "Model Number: 13 of 24 with model ConstantNaive for Validation 2\n",
      "13 - ConstantNaive with avg smape 57.88: \n",
      "Model Number: 14 of 24 with model AverageValueNaive for Validation 2\n",
      "14 - AverageValueNaive with avg smape 98.77: \n",
      "Model Number: 15 of 24 with model GLS for Validation 2\n",
      "15 - GLS with avg smape 77.32: \n",
      "Model Number: 16 of 24 with model ConstantNaive for Validation 2\n",
      "16 - ConstantNaive with avg smape 96.42: \n",
      "Model Number: 17 of 24 with model ConstantNaive for Validation 2\n",
      "17 - ConstantNaive with avg smape 96.42: \n",
      "Model Number: 18 of 24 with model ConstantNaive for Validation 2\n",
      "18 - ConstantNaive with avg smape 96.42: \n",
      "Model Number: 19 of 24 with model AverageValueNaive for Validation 2\n",
      "19 - AverageValueNaive with avg smape 96.43: \n",
      "Model Number: 20 of 24 with model AverageValueNaive for Validation 2\n",
      "20 - AverageValueNaive with avg smape 96.43: \n",
      "Model Number: 21 of 24 with model AverageValueNaive for Validation 2\n",
      "21 - AverageValueNaive with avg smape 68.83: \n",
      "Model Number: 22 of 24 with model AverageValueNaive for Validation 2\n",
      "22 - AverageValueNaive with avg smape 56.51: \n",
      "Model Number: 23 of 24 with model AverageValueNaive for Validation 2\n",
      "23 - AverageValueNaive with avg smape 91.95: \n",
      "Model Number: 24 of 24 with model GLS for Validation 2\n",
      "24 - GLS with avg smape 90.74: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 24 with model LastValueNaive for Validation 3\n",
      "📈 1 - LastValueNaive with avg smape 63.16: \n",
      "Model Number: 2 of 24 with model LastValueNaive for Validation 3\n",
      "2 - LastValueNaive with avg smape 65.29: \n",
      "Model Number: 3 of 24 with model LastValueNaive for Validation 3\n",
      "3 - LastValueNaive with avg smape 65.29: \n",
      "Model Number: 4 of 24 with model SeasonalNaive for Validation 3\n",
      "📈 4 - SeasonalNaive with avg smape 30.95: \n",
      "Model Number: 5 of 24 with model LastValueNaive for Validation 3\n",
      "5 - LastValueNaive with avg smape 70.14: \n",
      "Model Number: 6 of 24 with model LastValueNaive for Validation 3\n",
      "6 - LastValueNaive with avg smape 70.14: \n",
      "Model Number: 7 of 24 with model LastValueNaive for Validation 3\n",
      "7 - LastValueNaive with avg smape 70.14: \n",
      "Model Number: 8 of 24 with model SeasonalNaive for Validation 3\n",
      "8 - SeasonalNaive with avg smape 51.12: \n",
      "Model Number: 9 of 24 with model SeasonalNaive for Validation 3\n",
      "9 - SeasonalNaive with avg smape 37.38: \n",
      "Model Number: 10 of 24 with model SeasonalNaive for Validation 3\n",
      "10 - SeasonalNaive with avg smape 30.95: \n",
      "Model Number: 11 of 24 with model SeasonalNaive for Validation 3\n",
      "11 - SeasonalNaive with avg smape 30.95: \n",
      "Model Number: 12 of 24 with model SeasonalNaive for Validation 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 - SeasonalNaive with avg smape 72.85: \n",
      "Model Number: 13 of 24 with model ConstantNaive for Validation 3\n",
      "13 - ConstantNaive with avg smape 70.15: \n",
      "Model Number: 14 of 24 with model AverageValueNaive for Validation 3\n",
      "14 - AverageValueNaive with avg smape 78.24: \n",
      "Model Number: 15 of 24 with model GLS for Validation 3\n",
      "📈 15 - GLS with avg smape 24.16: \n",
      "Model Number: 16 of 24 with model ConstantNaive for Validation 3\n",
      "16 - ConstantNaive with avg smape 78.26: \n",
      "Model Number: 17 of 24 with model ConstantNaive for Validation 3\n",
      "17 - ConstantNaive with avg smape 78.26: \n",
      "Model Number: 18 of 24 with model ConstantNaive for Validation 3\n",
      "18 - ConstantNaive with avg smape 78.26: \n",
      "Model Number: 19 of 24 with model AverageValueNaive for Validation 3\n",
      "19 - AverageValueNaive with avg smape 78.27: \n",
      "Model Number: 20 of 24 with model AverageValueNaive for Validation 3\n",
      "20 - AverageValueNaive with avg smape 78.27: \n",
      "Model Number: 21 of 24 with model AverageValueNaive for Validation 3\n",
      "21 - AverageValueNaive with avg smape 24.71: \n",
      "Model Number: 22 of 24 with model AverageValueNaive for Validation 3\n",
      "22 - AverageValueNaive with avg smape 82.98: \n",
      "Model Number: 23 of 24 with model AverageValueNaive for Validation 3\n",
      "23 - AverageValueNaive with avg smape 36.09: \n",
      "Model Number: 24 of 24 with model GLS for Validation 3\n",
      "24 - GLS with avg smape 38.29: \n",
      "Validation Round: 4\n",
      "Model Number: 1 of 24 with model LastValueNaive for Validation 4\n",
      "📈 1 - LastValueNaive with avg smape 57.64: \n",
      "Model Number: 2 of 24 with model LastValueNaive for Validation 4\n",
      "📈 2 - LastValueNaive with avg smape 57.09: \n",
      "Model Number: 3 of 24 with model LastValueNaive for Validation 4\n",
      "3 - LastValueNaive with avg smape 57.09: \n",
      "Model Number: 4 of 24 with model SeasonalNaive for Validation 4\n",
      "📈 4 - SeasonalNaive with avg smape 53.01: \n",
      "Model Number: 5 of 24 with model LastValueNaive for Validation 4\n",
      "5 - LastValueNaive with avg smape 53.55: \n",
      "Model Number: 6 of 24 with model LastValueNaive for Validation 4\n",
      "6 - LastValueNaive with avg smape 53.55: \n",
      "Model Number: 7 of 24 with model LastValueNaive for Validation 4\n",
      "7 - LastValueNaive with avg smape 53.55: \n",
      "Model Number: 8 of 24 with model SeasonalNaive for Validation 4\n",
      "8 - SeasonalNaive with avg smape 56.0: \n",
      "Model Number: 9 of 24 with model SeasonalNaive for Validation 4\n",
      "9 - SeasonalNaive with avg smape 57.18: \n",
      "Model Number: 10 of 24 with model SeasonalNaive for Validation 4\n",
      "10 - SeasonalNaive with avg smape 53.01: \n",
      "Model Number: 11 of 24 with model SeasonalNaive for Validation 4\n",
      "11 - SeasonalNaive with avg smape 53.01: \n",
      "Model Number: 12 of 24 with model SeasonalNaive for Validation 4\n",
      "12 - SeasonalNaive with avg smape 53.54: \n",
      "Model Number: 13 of 24 with model ConstantNaive for Validation 4\n",
      "13 - ConstantNaive with avg smape 53.56: \n",
      "Model Number: 14 of 24 with model AverageValueNaive for Validation 4\n",
      "14 - AverageValueNaive with avg smape 59.55: \n",
      "Model Number: 15 of 24 with model GLS for Validation 4\n",
      "📈 15 - GLS with avg smape 52.54: \n",
      "Model Number: 16 of 24 with model ConstantNaive for Validation 4\n",
      "16 - ConstantNaive with avg smape 60.5: \n",
      "Model Number: 17 of 24 with model ConstantNaive for Validation 4\n",
      "17 - ConstantNaive with avg smape 60.5: \n",
      "Model Number: 18 of 24 with model ConstantNaive for Validation 4\n",
      "18 - ConstantNaive with avg smape 60.5: \n",
      "Model Number: 19 of 24 with model AverageValueNaive for Validation 4\n",
      "19 - AverageValueNaive with avg smape 60.52: \n",
      "Model Number: 20 of 24 with model AverageValueNaive for Validation 4\n",
      "20 - AverageValueNaive with avg smape 60.52: \n",
      "Model Number: 21 of 24 with model AverageValueNaive for Validation 4\n",
      "📈 21 - AverageValueNaive with avg smape 47.65: \n",
      "Model Number: 22 of 24 with model AverageValueNaive for Validation 4\n",
      "22 - AverageValueNaive with avg smape 64.5: \n",
      "Model Number: 23 of 24 with model AverageValueNaive for Validation 4\n",
      "23 - AverageValueNaive with avg smape 53.79: \n",
      "Model Number: 24 of 24 with model GLS for Validation 4\n",
      "24 - GLS with avg smape 54.03: \n",
      "Validation Round: 5\n",
      "Model Number: 1 of 24 with model LastValueNaive for Validation 5\n",
      "📈 1 - LastValueNaive with avg smape 12.36: \n",
      "Model Number: 2 of 24 with model LastValueNaive for Validation 5\n",
      "📈 2 - LastValueNaive with avg smape 11.8: \n",
      "Model Number: 3 of 24 with model LastValueNaive for Validation 5\n",
      "3 - LastValueNaive with avg smape 11.8: \n",
      "Model Number: 4 of 24 with model SeasonalNaive for Validation 5\n",
      "4 - SeasonalNaive with avg smape 12.4: \n",
      "Model Number: 5 of 24 with model LastValueNaive for Validation 5\n",
      "📈 5 - LastValueNaive with avg smape 10.81: \n",
      "Model Number: 6 of 24 with model LastValueNaive for Validation 5\n",
      "6 - LastValueNaive with avg smape 10.81: \n",
      "Model Number: 7 of 24 with model LastValueNaive for Validation 5\n",
      "7 - LastValueNaive with avg smape 10.81: \n",
      "Model Number: 8 of 24 with model SeasonalNaive for Validation 5\n",
      "8 - SeasonalNaive with avg smape 16.37: \n",
      "Model Number: 9 of 24 with model SeasonalNaive for Validation 5\n",
      "9 - SeasonalNaive with avg smape 21.59: \n",
      "Model Number: 10 of 24 with model SeasonalNaive for Validation 5\n",
      "10 - SeasonalNaive with avg smape 12.4: \n",
      "Model Number: 11 of 24 with model SeasonalNaive for Validation 5\n",
      "11 - SeasonalNaive with avg smape 12.4: \n",
      "Model Number: 12 of 24 with model SeasonalNaive for Validation 5\n",
      "12 - SeasonalNaive with avg smape 11.26: \n",
      "Model Number: 13 of 24 with model ConstantNaive for Validation 5\n",
      "13 - ConstantNaive with avg smape 10.81: \n",
      "Model Number: 14 of 24 with model AverageValueNaive for Validation 5\n",
      "14 - AverageValueNaive with avg smape 21.33: \n",
      "Model Number: 15 of 24 with model GLS for Validation 5\n",
      "15 - GLS with avg smape 17.46: \n",
      "Model Number: 16 of 24 with model ConstantNaive for Validation 5\n",
      "16 - ConstantNaive with avg smape 21.5: \n",
      "Model Number: 17 of 24 with model ConstantNaive for Validation 5\n",
      "17 - ConstantNaive with avg smape 21.5: \n",
      "Model Number: 18 of 24 with model ConstantNaive for Validation 5\n",
      "18 - ConstantNaive with avg smape 21.5: \n",
      "Model Number: 19 of 24 with model AverageValueNaive for Validation 5\n",
      "19 - AverageValueNaive with avg smape 21.51: \n",
      "Model Number: 20 of 24 with model AverageValueNaive for Validation 5\n",
      "20 - AverageValueNaive with avg smape 21.51: \n",
      "Model Number: 21 of 24 with model AverageValueNaive for Validation 5\n",
      "21 - AverageValueNaive with avg smape 12.69: \n",
      "Model Number: 22 of 24 with model AverageValueNaive for Validation 5\n",
      "22 - AverageValueNaive with avg smape 19.7: \n",
      "Model Number: 23 of 24 with model AverageValueNaive for Validation 5\n",
      "23 - AverageValueNaive with avg smape 12.41: \n",
      "Model Number: 24 of 24 with model GLS for Validation 5\n",
      "24 - GLS with avg smape 12.63: \n"
     ]
    }
   ],
   "source": [
    "single_junc_res = train_models_per_junction(data_junction_3, autots_param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3616acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_models_from_file():\n",
    "    base_dir = \"./results_per_junction\"\n",
    "    generic_model_dirs = \"junction_{0}\"\n",
    "    generic_fn = \"junction_{0}_trained_autots_model_junction_number_tuple.bin\"\n",
    "    \n",
    "    trained_model_junction_num_tuple_list = []\n",
    "    \n",
    "    for junction_number in range(1, 5):\n",
    "        filepath = \"/\".join(\n",
    "            [\n",
    "                base_dir, \n",
    "                generic_model_dirs.format(junction_number), \n",
    "                \"autots_model\", \n",
    "                generic_fn.format(junction_number)\n",
    "            ]\n",
    "        )\n",
    "                \n",
    "        with open(filepath, \"rb\") as f: # \"wb\" because we want to write in binary mode\n",
    "            trained_model_junction_num_tuple = pickle.load(f)  \n",
    "            \n",
    "        trained_model_junction_num_tuple_list.append(\n",
    "            trained_model_junction_num_tuple\n",
    "        )\n",
    "        \n",
    "    return trained_model_junction_num_tuple_list\n",
    "\n",
    "\n",
    "def create_best_model_scores_per_junction_bar_plot(best_model_junction_num_tuple_list):\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    \n",
    "    score_list = []\n",
    "    junction_num_list = []\n",
    "    color_list = []\n",
    "    \n",
    "    for autots_model, junction_num in best_model_junction_num_tuple_list:\n",
    "        model_results = autots_model.results(\"validation\")\n",
    "        \n",
    "        best_model_index = autots_model.best_model.index\n",
    "        \n",
    "        score = model_results.iloc[best_model_index][\"Score\"].values\n",
    "        \n",
    "        score_list.append(*score)\n",
    "        junction_num_list.append(junction_num)\n",
    "        color_list.append(junction_to_color_mapping[junction_num])\n",
    "        \n",
    "    ax.bar(junction_num_list, score_list, color=color_list)\n",
    "    \n",
    "    ax.set_xticks(junction_num_list)\n",
    "    ax.set_xticklabels(\n",
    "        map(lambda x: \"junction_{0}\".format(x), junction_num_list)\n",
    "    )\n",
    "    #ax.set_title(\"Number of datapoints available in the traffic dataset per junction\", fontsize=15)\n",
    "    #ax.set_xlabel(\"Junctions present in the traffic dataset\")\n",
    "    #ax.set_ylabel(\"Number of available datapoints\")\n",
    "    \n",
    "    #plt.savefig(\"./eda_plots/traffic_dataset_datapoint_per_junction_bar_plot.png\")\n",
    "    #plt.close(fig)\n",
    "    \n",
    "\n",
    "def create_model_count_in_best_worst_quarter_of_models_per_junction_bar_plot(\n",
    "    best_model_junction_num_tuple_list\n",
    "):\n",
    "    for model, junction_num in best_model_junction_num_tuple_list:\n",
    "        results = model.results(\"validation\")\n",
    "        val_results = results.loc[results[\"Runs\"] == 6].sort_values(by=[\"Score\"])\n",
    "        \n",
    "        n_quarter = round(len(val_results) / 4)\n",
    "        \n",
    "        quarter_best_models = val_results.head(n_quarter)[[\"Model\", \"ID\"]]\n",
    "        quarter_worst_models = val_results.tail(n_quarter)[[\"Model\", \"ID\"]]\n",
    "        \n",
    "        quarter_best_model_counts = quarter_best_models.groupby([\"Model\"]).count()\n",
    "        quarter_worst_model_counts = quarter_worst_models.groupby([\"Model\"]).count()\n",
    "        \n",
    "        fig, axs = plt.subplots(\n",
    "            1, \n",
    "            2, \n",
    "            figsize=(15,7),\n",
    "        )\n",
    "        \n",
    "        fig.suptitle(\n",
    "            (\n",
    "                \"Specific model count in best and worst\"      \n",
    "                \" performing models quarter on junction_{0} data\"\n",
    "            ).format(junction_num)\n",
    "        )\n",
    "        \n",
    "        axs[0].bar(\n",
    "            quarter_best_model_counts.index, \n",
    "            quarter_best_model_counts[\"ID\"],\n",
    "            color = junction_to_color_mapping[junction_num],\n",
    "        )\n",
    "        axs[0].set_title(\"Model count in best performing quarter of trained models\")\n",
    "\n",
    "\n",
    "        axs[1].bar(\n",
    "            quarter_worst_model_counts.index,\n",
    "            quarter_worst_model_counts[\"ID\"],\n",
    "            color = junction_to_color_mapping[junction_num],\n",
    "        )\n",
    "        axs[1].set_title(\"Model count in worst performing quarter of trained models\")\n",
    "        \n",
    "        # y-achse beschriften!!!!! ggf. auch x?!?!?!\n",
    "        \n",
    "        #plt.savefig()\n",
    "        #plt.close(fig)\n",
    "\n",
    "        \n",
    "        \n",
    "def create_model_count_in_best_worst_quarter_of_models_bar_plot(\n",
    "    best_model_junction_num_tuple_list\n",
    "):\n",
    "    all_junctions_best_quarter_models = pd.DataFrame()\n",
    "    all_junctions_worst_quarter_models = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    for model, junction_num in best_model_junction_num_tuple_list:\n",
    "        results = model.results(\"validation\")\n",
    "        val_results = results.loc[results[\"Runs\"] == 6].sort_values(by=[\"Score\"])\n",
    "        \n",
    "        n_quarter = round(len(val_results) / 4)\n",
    "        \n",
    "        quarter_best_models = val_results.head(n_quarter)[[\"Model\", \"ID\"]]\n",
    "        quarter_worst_models = val_results.tail(n_quarter)[[\"Model\", \"ID\"]]\n",
    "        \n",
    "        all_junctions_best_quarter_models = pd.concat(\n",
    "            [\n",
    "                all_junctions_best_quarter_models,\n",
    "                quarter_best_models,\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        all_junctions_worst_quarter_models = pd.concat(\n",
    "            [\n",
    "                all_junctions_worst_quarter_models,\n",
    "                quarter_worst_models,\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    quarter_best_model_counts = all_junctions_best_quarter_models.groupby([\"Model\"]).count()\n",
    "    quarter_worst_model_counts = all_junctions_worst_quarter_models.groupby([\"Model\"]).count()\n",
    "        \n",
    "    fig, axs = plt.subplots(\n",
    "        1, \n",
    "        2, \n",
    "        figsize=(15,7),\n",
    "    )\n",
    "        \n",
    "    fig.suptitle(\n",
    "        (\n",
    "            \"Specific model count in best and worst\"      \n",
    "            \" performing models quarter combined from all junctions\" \n",
    "        ).format(junction_num),\n",
    "        fontsize = 18,\n",
    "    )\n",
    "        \n",
    "    axs[0].bar(\n",
    "        quarter_best_model_counts.index, \n",
    "        quarter_best_model_counts[\"ID\"],    \n",
    "        color = \"silver\",    \n",
    "    )\n",
    "        \n",
    "    axs[0].set_title(\n",
    "        \"Model count in best performing quarter of trained models\",\n",
    "        fontsize = 14,\n",
    "    )\n",
    "\n",
    "    axs[1].bar(\n",
    "        quarter_worst_model_counts.index,\n",
    "        quarter_worst_model_counts[\"ID\"],\n",
    "        color = \"silver\",    \n",
    "    )\n",
    "    axs[1].set_title(\n",
    "        \"Model count in worst performing quarter of trained models\",\n",
    "        fontsize = 14,\n",
    "    )\n",
    "    \n",
    "    plt.savefig(\"./combined_result_plots/model_count_in_best_worst_quarter_of_models_bar_plot.png\")\n",
    "    #plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def create_backforecast_plot(\n",
    "    time_series_data,\n",
    "    best_model_junction_num_tuple_list, \n",
    "    start_date = datetime(2015, 11, 1, 0, 0, 0)\n",
    "):\n",
    "    fig, axs = plt.subplots(\n",
    "        2, \n",
    "        2, \n",
    "        figsize=(20,15),\n",
    "    )\n",
    "    \n",
    "    column = 0\n",
    "    row = 0\n",
    "    \n",
    "    time_series_data_groups = time_series_data.groupby([\"Junction\"])\n",
    "    \n",
    "    for model, junction_num in best_model_junction_num_tuple_list:\n",
    "        filename = (\"junction_{0}_best_trained_model_junction_\"       \n",
    "                    \"backforecast.csv\").format(junction_num)\n",
    "        \n",
    "        working_directory =os.getcwd()  # da lassen? eig nicht nötig?!\n",
    "        base_path = \"results_per_junction/junction_{0}/autots_model\".format(junction_num)\n",
    "        \n",
    "        complete_path = \"/\".join([working_directory, base_path, filename])\n",
    "        \n",
    "        junction_backforecast = pd.read_csv(\n",
    "            complete_path, \n",
    "            parse_dates=True,\n",
    "            header=0,\n",
    "            names=[\"DateTime\", \"Vehicles\"],\n",
    "            index_col=\"DateTime\",\n",
    "        )\n",
    "        \n",
    "        junction_data = time_series_data_groups.get_group(junction_num)[\"Vehicles\"]\n",
    "                \n",
    "        reduced_forecast = junction_backforecast[start_date:]\n",
    "        reduced_data = junction_data[start_date:]\n",
    "        \n",
    "        axs[column, row].plot(\n",
    "            reduced_data, \n",
    "            color = junction_to_color_mapping[junction_num],\n",
    "            label = \"junction_{0}\".format(junction_num)\n",
    "        )\n",
    "        \n",
    "        axs[column, row].plot(\n",
    "            reduced_forecast,\n",
    "            color = \"black\",\n",
    "            label = \"model_forecast\" if junction_num ==1 else None\n",
    "        )\n",
    "        \n",
    "        axs[column, row].set_title(\n",
    "            \"Kreuzung {0}\".format(junction_num),\n",
    "            fontsize = 22,\n",
    "        )\n",
    "        \n",
    "        axs[column, row].tick_params(labelsize=16)\n",
    "        axs[column, row].tick_params(axis='x', labelrotation = 45)\n",
    "        \n",
    "        column = 0 if junction_num % 2 == 0 else column + 1\n",
    "        row = row + 1 if column % 2 == 0 else row\n",
    "        \n",
    "    leg = fig.legend(\n",
    "        fontsize=\"xx-large\", \n",
    "        ncol = 2,\n",
    "        bbox_to_anchor =(0.65, 0.095)\n",
    "    )\n",
    "    \n",
    "    for line in leg.get_lines():\n",
    "            line.set_linewidth(6)\n",
    "            \n",
    "    fig.tight_layout(h_pad=2.0)\n",
    "    fig.subplots_adjust(bottom=0.175)\n",
    "    \n",
    "    fig.savefig(\n",
    "        \"./combined_result_plots/backforecast_per_junction_plot.png\",\n",
    "        facecolor = \"w\",\n",
    "    )\n",
    "    \n",
    "    #plt.close(fig)\n",
    "\n",
    "    \n",
    "def save_best_quarter_of_models_per_junction(best_model_junction_num_tuple_list):\n",
    "    generic_path = (\n",
    "        \" ./results_per_junction/{0}/\"\n",
    "        \"best_quarter_of_trained_models/\"\n",
    "        \"models.csv\"\n",
    "    )\n",
    "    \n",
    "    for model, junction_num in best_model_junction_num_tuple_list:\n",
    "        results = model.results(\"validation\")\n",
    "        val_results = results.loc[results[\"Runs\"] == 6].sort_values(by=[\"Score\"])\n",
    "        \n",
    "        n_quarter = round(len(val_results) / 4)\n",
    "        \n",
    "        model.export_template(\n",
    "            generic_path.format(junction_num), \n",
    "            models=\"best\",          \n",
    "            n=n_quarter, \n",
    "        )\n",
    "        \n",
    "        \n",
    "def safe_model_occurences_in_best_quarter_as_latex_table_per_junction(\n",
    "    best_model_junction_num_tuple_list\n",
    "):\n",
    "    working_directory =os.getcwd() # notwendig? denke nicht!\n",
    "    generic_base_path = \"/\".join(\n",
    "        [\n",
    "            working_directory,\n",
    "            \"results_per_junction/junction_{0}/result_tables_as_latex/\"\n",
    "        ]\n",
    "    )\n",
    "    fn_best = \"model_occurence_best_quarter_junction_{0}.tex\"\n",
    "    fn_worst = \"model_occurence_worst_quarter_junction_{0}.tex\"\n",
    "    \n",
    "    for model, junction_num in best_model_junction_num_tuple_list:\n",
    "        results = model.results(\"validation\")\n",
    "        val_results = results.loc[results[\"Runs\"] == 6].sort_values(by=[\"Score\"])\n",
    "        \n",
    "        n_quarter = round(len(val_results) / 4)\n",
    "        \n",
    "        quarter_best_models = val_results.head(n_quarter)[[\"Model\", \"ID\"]]\n",
    "        quarter_worst_models = val_results.tail(n_quarter)[[\"Model\", \"ID\"]]\n",
    "        \n",
    "        quarter_best_model_counts = quarter_best_models.groupby([\"Model\"]).count()\n",
    "        quarter_worst_model_counts = quarter_worst_models.groupby([\"Model\"]).count()\n",
    "        \n",
    "        quarter_best_model_counts.columns = [\"occurence\"]\n",
    "        quarter_worst_model_counts.columns = [\"occurence\"]\n",
    " \n",
    "\n",
    "        best_path = \"\".join(\n",
    "            [\n",
    "                generic_base_path.format(junction_num),\n",
    "                fn_best.format(junction_num)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        worst_path = \"\".join(\n",
    "            [\n",
    "                generic_base_path.format(junction_num),\n",
    "                fn_worst.format(junction_num)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        quarter_best_model_counts.to_latex(\n",
    "            buf = best_path,\n",
    "            header = True,\n",
    "            index = False,\n",
    "            longtable = True,\n",
    "            #caption = ,\n",
    "        )\n",
    "        \n",
    "        quarter_worst_model_counts.to_latex(\n",
    "            buf = worst_path,\n",
    "            header = True,\n",
    "            index = False,\n",
    "            longtable = True,\n",
    "            #caption = ,\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "def safe_complete_autots_results_as_latex_table_per_junction(\n",
    "    best_model_junction_num_tuple_list\n",
    "):\n",
    "    generic_base_path = \"./results_per_junction/junction_{0}/result_tables_as_latex/\"\n",
    "    \n",
    "    fn_train_results = \"autots_model_train_results_junction_{0}.tex\"\n",
    "    fn_val_results = \"autots_model_val_results_junction_{0}.tex\"\n",
    "    \n",
    "    \n",
    "    for model, junction_num in best_model_junction_num_tuple_list:\n",
    "        train_results = model.results()\n",
    "        val_results = model.results(\"validation\")\n",
    "        \n",
    "        train_path = \"\".join(\n",
    "            [\n",
    "                generic_base_path.format(junction_num),\n",
    "                fn_train_results.format(junction_num),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        val_path = \"\".join(\n",
    "            [\n",
    "                generic_base_path.format(junction_num),\n",
    "                fn_val_results.format(junction_num),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        train_results.to_latex(\n",
    "            buf = train_path,\n",
    "            header = True,\n",
    "            index = False,\n",
    "            longtable = True,\n",
    "            #caption = ,\n",
    "        )\n",
    "        \n",
    "        val_results.to_latex(\n",
    "            buf = val_path,\n",
    "            header = True,\n",
    "            index = False,\n",
    "            longtable = True,\n",
    "            #caption = ,\n",
    "        )\n",
    "\n",
    "        \n",
    "    \n",
    "def create_report_materials_out_of_trained_models():\n",
    "    trained_model_junction_num_tuple_list = load_trained_models_from_file()\n",
    "    \n",
    "    create_best_model_scores_per_junction_bar_plot(  # => funk nutzen für tabelle!!!!!!!!!!!!!!!!!!!\n",
    "        trained_model_junction_num_tuple_list\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #create_model_count_in_best_worst_quarter_of_models_per_junction_bar_plot(\n",
    "    #    trained_model_junction_num_tuple_list\n",
    "    #)\n",
    "    \n",
    "    #create_model_count_in_best_worst_quarter_of_models_bar_plot(\n",
    "    #    trained_model_junction_num_tuple_list\n",
    "    #)\n",
    "    \n",
    "    #safe_model_occurences_in_best_quarter_as_latex_table_per_junction(\n",
    "    #    trained_model_junction_num_tuple_list\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    #safe_complete_autots_results_as_latex_table_per_junction(\n",
    "    #    trained_model_junction_num_tuple_list\n",
    "    #)\n",
    "    \n",
    "    #create_backforecast_plot(\n",
    "    #    data,\n",
    "    #    trained_model_junction_num_tuple_list, \n",
    "    #    datetime(2017, 6, 15, 0, 0, 0)\n",
    "    #)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # avg score by model/ model group\n",
    "    \n",
    "    # ggf. generation loss per junction plot????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26938b5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results_per_junction/junction_1/autots_model/junction_1_trained_autots_model_junction_number_tuple.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_report_materials_out_of_trained_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [107]\u001b[0m, in \u001b[0;36mcreate_report_materials_out_of_trained_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_report_materials_out_of_trained_models\u001b[39m():\n\u001b[0;32m--> 393\u001b[0m     trained_model_junction_num_tuple_list \u001b[38;5;241m=\u001b[39m \u001b[43mload_trained_models_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     create_best_model_scores_per_junction_bar_plot(  \u001b[38;5;66;03m# => funk nutzen für tabelle!!!!!!!!!!!!!!!!!!!\u001b[39;00m\n\u001b[1;32m    396\u001b[0m         trained_model_junction_num_tuple_list\n\u001b[1;32m    397\u001b[0m     )\n",
      "Input \u001b[0;32mIn [107]\u001b[0m, in \u001b[0;36mload_trained_models_from_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m junction_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      9\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     10\u001b[0m         [\n\u001b[1;32m     11\u001b[0m             base_dir, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m         ]\n\u001b[1;32m     16\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f: \u001b[38;5;66;03m# \"wb\" because we want to write in binary mode\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         trained_model_junction_num_tuple \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)  \n\u001b[1;32m     21\u001b[0m     trained_model_junction_num_tuple_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     22\u001b[0m         trained_model_junction_num_tuple\n\u001b[1;32m     23\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results_per_junction/junction_1/autots_model/junction_1_trained_autots_model_junction_number_tuple.bin'"
     ]
    }
   ],
   "source": [
    "create_report_materials_out_of_trained_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ce03d",
   "metadata": {},
   "source": [
    "fzgsdhgfsdghfhjsdghfjsdgfsdgf\n",
    "\n",
    "sdhfjksdhfkjsdhhfjksdhfkjsd\n",
    "\n",
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png)\n",
    "\n",
    "sahjdgasjhghdhjasgdhjasgd\n",
    "\n",
    "ashdsahdkjsahdkjsahd\n",
    "\n",
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png)\n",
    "\n",
    "\n",
    "\n",
    "ashndashjkdhasjkdh\n",
    "\n",
    "asghdjasgdgshajdgh\n",
    "\n",
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png)\n",
    "\n",
    "\n",
    "shakjdhukashdkjashdjkas\n",
    "\n",
    "jsakhdjhsadkjhaskdh\n",
    "\n",
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png)\n",
    "\n",
    "\n",
    "sdjadfukdshfjksdhfjksdh\n",
    "\n",
    "sakdhaskjdhasjkhjdkjash\n",
    "\n",
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png)\n",
    "\n",
    "\n",
    "jkdshfjkdshjfsdhfsdfhj\n",
    "\n",
    "hdsfhsdkjfhsdjkhfjksdhf\n",
    "\n",
    "![datapoints per junction](./eda_plots/traffic_dataset_vehicle_count_per_junction_bar_plot.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_best_model_scores_per_junction_table(best_model_junction_num_tuple_list):\n",
    "    score_list = []\n",
    "    junction_num_list = []\n",
    "    model_name_list = []\n",
    "    \n",
    "    for autots_model, junction_num in best_model_junction_num_tuple_list:\n",
    "        model_results = autots_model.results(\"validation\")\n",
    "        \n",
    "        best_model_index = autots_model.best_model.index\n",
    "        \n",
    "        score = model_results.iloc[best_model_index][\"Score\"].values\n",
    "        \n",
    "        score_list.append(*score)\n",
    "        junction_num_list.append(junction_num)\n",
    "        model_name_list.append(autots_model.best_model_name)\n",
    "        \n",
    "    best_model_result_table = pd.DataFrame(\n",
    "        {\n",
    "            \"Kreuzung\": junction_num_list,\n",
    "            \"Modell\": model_name_list,\n",
    "            \"Zielmetrikwert\": score_list,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return best_model_result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8128c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_junction_num_tuple_list = load_trained_models_from_file()\n",
    "    \n",
    "result_table = create_best_model_scores_per_junction_table(\n",
    "        trained_model_junction_num_tuple_list\n",
    "    )\n",
    "    \n",
    "from IPython.display import HTML\n",
    "HTML(result_table.to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54923ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median runtime per algo\n",
    "# latex und csv tabellen abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba3c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec913ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
